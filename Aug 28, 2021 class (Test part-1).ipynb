{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 => Write a Python Program to count the number of words and tell how many times that word occurs and print that in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the sentence : Nory was a Catholic because her mother was a Catholic, and Nory's mother was a Catholic because her father was a Catholic, and her father was a Catholic because his mother was a Catholic, or had been.\n",
      "\n",
      "Checking the split :- \n",
      "['Nory', 'was', 'a', 'Catholic', 'because', 'her', 'mother', 'was', 'a', 'Catholic,', 'and', \"Nory's\", 'mother', 'was', 'a', 'Catholic', 'because', 'her', 'father', 'was', 'a', 'Catholic,', 'and', 'her', 'father', 'was', 'a', 'Catholic', 'because', 'his', 'mother', 'was', 'a', 'Catholic,', 'or', 'had', 'been.']\n",
      "\n",
      "Count per words :- \n",
      "{'Nory': 1, 'was': 6, 'a': 6, 'Catholic': 3, 'because': 3, 'her': 3, 'mother': 3, 'Catholic,': 3, 'and': 2, \"Nory's\": 1, 'father': 2, 'his': 1, 'or': 1, 'had': 1, 'been.': 1}\n"
     ]
    }
   ],
   "source": [
    "sentence = input(\"Enter the sentence : \")\n",
    "\n",
    "countPerWord = {}\n",
    "newSentence1 = sentence.split(\" \")\n",
    "print()\n",
    "print(\"Checking the split :- \")\n",
    "print(newSentence1)\n",
    "newSentence2 = sentence.split(\" \")\n",
    "for word in newSentence1:\n",
    "    count = 0\n",
    "    for check in newSentence2:\n",
    "        if(word == check):\n",
    "            count = count+1\n",
    "    countPerWord[word] = count\n",
    "             \n",
    "print()\n",
    "print(\"Count per words :- \")\n",
    "print(countPerWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 => Input a string and check if its a Pallindrone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the word to be checked : madam\n",
      "\n",
      "Palindrome\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter the word to be checked : \")\n",
    "\n",
    "newWord = \"\"\n",
    "for i in range((len(word)-1) , -1, -1):\n",
    "    newWord = newWord + word[i]\n",
    "\n",
    "print()\n",
    "if(newWord == word):\n",
    "    print(\"Palindrome\")\n",
    "else:\n",
    "    print(\"Not a palindrome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3 => Explain what is Overfitting and Underfitting.\n",
    "\n",
    "<strong>Overfitting</strong> : When the model is trained on large no. of independent features such that it performs extremely well on the train dataset whereas very bad on the test dataset, then this condition is called overfitting. Here, bias is low and variance is high. The model gets confused when we pass new data for testing, and as a result it performs badly, because, at the end we are mostly concerned whether it is able to predict new data correctly or not (which is the test data).\n",
    "\n",
    "<strong>Underfitting</strong> : When the model is trained on very less no. of independent features such that it performs badly on both the train dataset and test dataset, then this condition is called underfitting. Here both the bias and variance is very high which means that the error is also very high. For a perfect model, both bias and variance should be as low as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4 => Explain the types of Preprocessing done before feeding to the ML algorithm.\n",
    "\n",
    "There are many types of preprocessing that is done which are as follows :- \n",
    "1. Perform EDA like analyze, visualize, missing value treatment, outlier removal etc.\n",
    "\n",
    "2. After performing EDA, we can select which features are important for feeding the algorithm. This can be done with the help of <strong>pearson correlation</strong> in which we can check which independent features are impacting the dependent feature. It ranges from -1 to +1, where -1 indicates a high negative correlation, +1 indicates a high positive correlation and 0 indicates no correlation at all.\n",
    "\n",
    "\n",
    "3. Most of the ML algos understands numbers only, so we convert categorical features into numerical features before feeding into the ML algos using the techniques like <strong>one-hot encoding</strong>, <strong>label encoding</strong>, <strong>ordinal encoding</strong> etc. \n",
    "\n",
    "3.1. In <strong>one-hot encoding</strong>, the categorical feature is converted into 0's and 1's in seperate additional columns. \n",
    "\n",
    "3.2. In <strong>label encoding</strong>, the categorical feature is converted into numbers based on the alphabetical order of the letters of each record in that categorical feature.\n",
    "\n",
    "3.3. In <strong>ordinal encoding</strong>, the categorical feature is converted into numbers based on the rank of the classes in that categorical feature.\n",
    "\n",
    "4. All independent features may be in different range of values,, so we can bring all of them in one common range so that the weight on all independent features is comparable and the ML algo is fair with its decision on new test data. This can be done using :-\n",
    "\n",
    "4.1. <strong>Normalization</strong> = Using this, we bring the values in the range of 0 to 1, we use MinMaxScalar() for this.\n",
    "\n",
    "4.2. <strong>Standardization</strong> = Using this, we bring the values in the range of -1 to 1, which is the normal distribution. We use StandardScalar() for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5 => Explain the steps in a ML project lifecycle.\n",
    "\n",
    "The steps are as follows :-\n",
    "1. Frame the problem statement\n",
    "2. Data collection\n",
    "3. Data Analysis including preprocessing and exploration using EDA\n",
    "4. Data Preparation for feeding into ML algo\n",
    "5. Creating a model using various ML algo\n",
    "6. Fine tune the model.\n",
    "7. Deployement into production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
